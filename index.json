{
  "release-notes.html": {
    "href": "release-notes.html",
    "title": "Cursively Release Notes | Cursively",
    "keywords": "Cursively Release Notes 1.0.0 Initial release."
  },
  "index.html": {
    "href": "index.html",
    "title": "Cursively | Cursively",
    "keywords": "Cursively A fast, RFC 4180 -conforming CSV reading library for .NET. Written in C#. Fully supports all UTF-8 encoded byte streams. Other encodings will work as well, as long as the bytes 0x0A , 0x0D , 0x22 , and 0x2C are all guaranteed to mean the same thing that they mean in ASCII / UTF-8, and as long as the encoding defines no other byte sequences which identify the Unicode code points for '\\n' , '\\r' , '\"' , or ',' , respectively. In practice, this means that most \"Extended ASCII\" code pages will probably work, probably including all SBCS. Many \"Extended ASCII\" DBCS will probably work too, but it looks like Shift-JIS will not work. Notably, this library will fail to yield the correct result when used with byte streams encoded in any variant of UTF-16 or UTF-32, even with a BOM header. If you require that support, there are other libraries that should work for you. Fully supports all streams that completely conform to the RFC 4180 format, and defines rules for how to handle streams that break certain rules of RFC 4180 in a way that seems to be consistent with other popular tools, at a minor speed penalty. This library exists because the original developer was unsatisfied with the performance characteristics of raw CSV processing tools. Everything out there seemed to have some combination of these flaws: Tons of managed heap allocations on hot paths, often baked into the API requirements Decoding to UTF-16LE before scanning for critical bytes, which could be considered a subset of: The design forces a ton of processing to happen on the input which the caller might not even care about Omitting important parts of RFC 4180 Disappointing options for mitigating DDoS risk \"RFC 4180 over UTF-8\" is a very simple byte stream format, and the state machine requires only a few extra states to define how to handle all UTF-8 streams that are non-RFC 4180, so it seemed odd that there wasn't a reader without these flaws. With Cursively, each stream only strictly requires a grand total of two objects to be allocated on the managed heap*, *in case this is too much, both could be reset and put into a pool to be reused for processing other streams processing happens directly on the input bytes (no decoding is done by Cursively itself), the only processing that Cursively necessarily does is the bare minimum needed to describe the data to the caller, inputs that conform to RFC 4180* are processed according to all the rules of RFC 4180, and *inputs that do not conform to RFC 4180 are handled according to consistent, intuitive rules there is a very low risk* of DDoS directly from using Cursively, and the caller has the tools that they need in order to prevent (or respond to) attacks in a more \"natural\" way than other CSV libraries that the developer has seen. *There is no such thing as \"risk-free\" in our world. Cursively itself cannot eliminate the risk of attacks that use it as a vector to exploit defects in CoreFX / C# compiler / runtime / OS / hardware. Future enhancements may add support for byte streams in other encodings if there's demand for it, but not at the expense of anything that matters to the \"RFC 4180 over UTF-8\" use case."
  },
  "api/Cursively.html": {
    "href": "api/Cursively.html",
    "title": "Namespace Cursively | Cursively",
    "keywords": "Namespace Cursively Classes CsvReaderVisitorBase Base class for listeners that process a stream of RFC 4180 (CSV) tokens from an instance of CsvTokenizer . CsvTokenizer Tokenizes a byte stream into CSV fields. The processing follows the guidelines set out in RFC 4180 unless and until the stream proves to be in an incompatible format, in which case a set of additional rules kick in to ensure that all streams are still compatible. The byte stream is tokenized according to the rules of the ASCII encoding. This makes it compatible with any encoding that encodes 0x0A, 0x0D, 0x22, and 0x2C the same way that ASCII encodes them. UTF-8 and Extended ASCII SBCS are notable examples of acceptable encodings. UTF-16 is a notable example of an unacceptable encoding; trying to use this class to process text encoded in an unacceptable encoding will yield undesirable results without any errors. All bytes that appear in the stream except 0x0A, 0x0D, 0x22, and 0x2C are unconditionally treated as data and passed through as-is. It is the consumer's responsibility to handle (or not handle) NUL bytes, invalid UTF-8, leading UTF-8 BOM, or any other quirks that come with the territory of text processing."
  },
  "api/Cursively.CsvTokenizer.html": {
    "href": "api/Cursively.CsvTokenizer.html",
    "title": "Class CsvTokenizer | Cursively",
    "keywords": "Class CsvTokenizer Tokenizes a byte stream into CSV fields. The processing follows the guidelines set out in RFC 4180 unless and until the stream proves to be in an incompatible format, in which case a set of additional rules kick in to ensure that all streams are still compatible. The byte stream is tokenized according to the rules of the ASCII encoding. This makes it compatible with any encoding that encodes 0x0A, 0x0D, 0x22, and 0x2C the same way that ASCII encodes them. UTF-8 and Extended ASCII SBCS are notable examples of acceptable encodings. UTF-16 is a notable example of an unacceptable encoding; trying to use this class to process text encoded in an unacceptable encoding will yield undesirable results without any errors. All bytes that appear in the stream except 0x0A, 0x0D, 0x22, and 0x2C are unconditionally treated as data and passed through as-is. It is the consumer's responsibility to handle (or not handle) NUL bytes, invalid UTF-8, leading UTF-8 BOM, or any other quirks that come with the territory of text processing. Inheritance Object CsvTokenizer Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : Cursively Assembly : Cursively.dll Syntax public class CsvTokenizer Remarks Each instance of this class expects to process all data from one stream, represented as zero or more ProcessNextChunk(ReadOnlySpan<Byte>, CsvReaderVisitorBase) followed by one ProcessEndOfStream(CsvReaderVisitorBase) , before moving on to another stream. An instance may be reused after a stream has been fully processed, but each instance is also very lightweight, so it is recommended that callers simply create a new instance for each stream that needs to be processed. RFC 4180 leaves a lot of wiggle room for implementers. The following section explains how this implementation resolves ambiguities in the spec, explains where and why we deviate from it, and offers clarifying notes where the spec appears to have \"gotchas\", in the order that the relevant items appear in the spec, primarily modeled off of how Josh Close's CsvHelper library handles the same situations: Finally, the spec has a lot to say about double quotes. This implementation follows the rules that it expressly lays out, but there are some \"gotchas\" that follow from the spec leaving it open-ended how implementations should deal with various streams that include double quotes which do not completely enclose fields, resolved as follows: If a double quote is encountered at the very beginning of a field, then all characters up until the next unescaped double quote or the end of the stream (whichever comes first) are considered to be part of the data for that field (we do translate escaped double quotes for convenience). This includes line ending characters, even though Excel seems to only make that happen if the field counts matching up. If parsing stopped at an unescaped double quote, but there are still more bytes after that double quote before the next delimiter, then all those bytes will be treated verbatim as part of the field's data (double quotes are no longer special at all for the remainder of the field). Double quotes encountered at any other point are included verbatim as part of the field with no special processing. var visitor = new MyVisitorSubclass(); var tokenizer = new CsvTokenizer(); tokenizer.ProcessNextChunk(File.ReadAllBytes(\"...\"), visitor); tokenizer.ProcessEndOfStream(visitor); using (var stream = File.OpenRead(\"...\")) { var visitor = new MyVisitorSubclass(); var tokenizer = new CsvTokenizer(); var buffer = new byte[81920]; int lastRead; while ((lastRead = stream.Read(buffer, 0, buffer.Length)) != 0) { tokenizer.ProcessNextChunk(new ReadOnlySpan<byte>(buffer, 0, lastRead), visitor); } tokenizer.ProcessEndOfStream(visitor); } Methods | Improve this Doc View Source ProcessEndOfStream(CsvReaderVisitorBase) Informs this tokenizer that the last chunk of data in the stream has been read, and so we should make any final interactions with the CsvReaderVisitorBase and reset our state to prepare for the next stream. Declaration public void ProcessEndOfStream(CsvReaderVisitorBase visitor) Parameters Type Name Description CsvReaderVisitorBase visitor The CsvReaderVisitorBase to interact with, or null if we should simply advance the parser state. Remarks If ProcessNextChunk(ReadOnlySpan<Byte>, CsvReaderVisitorBase) has never been called (or has not been called since the last time that this method was called), then this method will do nothing. | Improve this Doc View Source ProcessNextChunk(ReadOnlySpan<Byte>, CsvReaderVisitorBase) Accepts the next (or first) chunk of data in the CSV stream, and informs an instance of CsvReaderVisitorBase what it contains. Declaration public void ProcessNextChunk(ReadOnlySpan<byte> chunk, CsvReaderVisitorBase visitor) Parameters Type Name Description ReadOnlySpan < Byte > chunk A ReadOnlySpan<T> containing the next chunk of data. CsvReaderVisitorBase visitor The CsvReaderVisitorBase to interact with, or null if we should simply advance the parser state. Remarks If chunk is empty, this method will do nothing."
  },
  "api/Cursively.CsvReaderVisitorBase.html": {
    "href": "api/Cursively.CsvReaderVisitorBase.html",
    "title": "Class CsvReaderVisitorBase | Cursively",
    "keywords": "Class CsvReaderVisitorBase Base class for listeners that process a stream of RFC 4180 (CSV) tokens from an instance of CsvTokenizer . Inheritance Object CsvReaderVisitorBase Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : Cursively Assembly : Cursively.dll Syntax public abstract class CsvReaderVisitorBase Remarks Remarks on the documentation of individual abstract methods indicate when the tokenizer is legally allowed to call that method. Fields | Improve this Doc View Source Null An implementation of CsvReaderVisitorBase that does nothing when it sees any of the tokens. Declaration public static readonly CsvReaderVisitorBase Null Field Value Type Description CsvReaderVisitorBase Methods | Improve this Doc View Source VisitEndOfField(ReadOnlySpan<Byte>) Visits the last part of a field's data. Declaration public abstract void VisitEndOfField(ReadOnlySpan<byte> chunk) Parameters Type Name Description ReadOnlySpan < Byte > chunk The data from the last part of the field. Remarks This method may be called at any time. Any method, including this one, may be called directly after a call to this method. This method may be called without a preceding VisitPartialFieldContents(ReadOnlySpan<Byte>) call, if the field's entire data is contained within the given chunk. | Improve this Doc View Source VisitEndOfRecord() Notifies that all fields in the current record have been visited. Declaration public abstract void VisitEndOfRecord() Remarks This method may only be called as the very next method that gets called after a call to VisitEndOfField(ReadOnlySpan<Byte>) . Only VisitPartialFieldContents(ReadOnlySpan<Byte>) and VisitEndOfField(ReadOnlySpan<Byte>) may be called directly after a call to this method. | Improve this Doc View Source VisitPartialFieldContents(ReadOnlySpan<Byte>) Visits part of a field's data. Declaration public abstract void VisitPartialFieldContents(ReadOnlySpan<byte> chunk) Parameters Type Name Description ReadOnlySpan < Byte > chunk The data from this part of the field. Remarks This method may be called at any time. Only VisitPartialFieldContents(ReadOnlySpan<Byte>) and VisitEndOfField(ReadOnlySpan<Byte>) may be called directly after a call to this method. There are multiple reasons why this method may be called instead of going straight to calling VisitEndOfField(ReadOnlySpan<Byte>) :"
  }
}